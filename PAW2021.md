# PAW 2021
## Participants

### Rob Hamilton
#### Biography
Composer and researcher Rob Hamilton explores the converging spaces between sound, music and interaction. His creative practice includes mixed and virtual-reality performance works built within fully rendered networked game environments, procedural music engines and mobile musical ecosystems. His research focuses on the cognitive implications of sonified musical gesture and motion and the role of perceived space in the creation and enjoyment of sound and music. Dr. Hamilton received his Ph.D. from Stanford University’s Center for Computer Research in Music and Acoustics (CCRMA) and currently serves as Associate Professor of Music and Media and Head of the Department of Arts at Rensselaer Polytechnic Institute in Troy, NY, USA.

#### Talk Description:

**Virtual Musical Instrument Design for the 21st Century**

Over the past decade, consumer-based virtual reality hardware and software platforms have become significantly more affordable and accessible to the general public. At the same time, virtual and augmented reality development toolkits grounded in game and mobile application design paradigms have similarly become more user friendly, opening up opportunities for artists, musicians and creatives of all backgrounds to help shape the look, feel and, perhaps most importantly, the sound of the ‘metaverse’ writ large. This talk will explore the role of musicians and digital luthiers alike in the field of Musical XR, targeting the creation and composition of dynamic and procedural real-time musical instruments and systems.

#### Workshop Description:

**Building Interactive Procedural Music Systems for Unreal Engine 4**

For artists and designers seeking to build software-based dynamic and procedural audio and music systems, Epic Games’ Unreal 4 gaming engine offers a robust and battle-tested codebase optimized for real-time multi-user interaction. Capable of rendering visual assets with astonishing clarity and realism, Unreal 4 also boasts native Open Sound Control (OSC) support, as well as a suite of native procedural audio components for real-time audio synthesis. This workshop will explore the use of Unreal Engine 4 for building interactive musical systems using Unreal’s Blueprint workflow programming environment, OSC, and Unreal’s own synthesis components. 


#### Downloads/Requirements:

Unreal Engine 4 for Windows PC, Mac OSX or Linux. 
Microsoft Visual Studio
Target Software for Open Sound Control

Unreal Engine 4 for Windows PC, Mac OX or Linux. 

This workshop will focus on using Unreal Engine v. 4.27, though most recent versions will also work. (please note, a free Epic Games account may be necessary to access all features of the Unreal Engine). If you wish to run Unreal during the workshop please make sure it and Visual Studio are downloaded and installed prior to arrival, as the packages are quite large (~40 GB).

https://www.unrealengine.com/en-US/download

Microsoft Visual Studio

While we will focus primarily on using Epic’s Blueprint scripting interface with Unreal, Microsoft Visual Studio is needed to compile C++ plugins and during the build process. Visual Studio is easy to integrate with Unreal:

https://docs.unrealengine.com/4.27/en-US/ProductionPipelines/DevelopmentSetup/VisualStudioSetup/

Unreal Engine 4 can be run on Windows PC, Mac OS and Linux. For the newest Apple machines with M1 and greater processors, there seem to be some potential issues with running all of Unreal’s features:
https://medium.com/techiepedia/setting-up-unreal-engine-m1-macbook-for-c-game-development-eb40c12237d1

Getting Started with Unreal Engine 4.27 for Linux
https://docs.unrealengine.com/4.27/en-US/SharingAndReleasing/Linux/BeginnerLinuxDeveloper/SettingUpAnUnrealWorkflow/

Target Software for Open Sound Control

Using Open Sound Control (OSC) this workshop will show how to link action and motion in Unreal to synthesis processes in an external audio programming environment. Please make sure you have some audio programming environment capable of receiving and sending Open Sound Control packages such as Pure Data, Supercollider, Max/MSP, ChucK.


### Michael Bolufer
#### Biography
Michaël Bolufer, director, writer, technical director at Plip! Animation and Studio Manette.Michaël has been working for almost 20 years between the animation and video game industries. In this "industrial in-between", he created in 2016 "Mr.Carton", the first series made with a game engine. Since then, he has participated in many series and VR film projects as a "real-time" technical art director.In 2020 he co-founded with Thibault Noyer the production company Plip! Animation and Studio Manette (in association with Caribara Animation), a studio specialized in the production of real-time films. He also continues to write and direct.

#### Talk Description:

**Video game engine as media creation Swiss army knife**

From fully featured AAA game engine to open source tools libraries, video game tools of all kind now constitute a rich and varied ecosystem. Many of these tools can be diverted from their original usage and relied upon as a basis for realtime media creation and especially audio. In the animation studio "Studio Manette", it is demonstrated daily with their production pipeline fully based on typical video game patterns and tools.



### Stefania Serafin
#### Biography
Stefania Serafin is professor of Sonic interaction design at Aalborg University in Copenhagen. She is the President of the Sound and Music Computing association, Project Leader of the Nordic Sound and Music Computing network and lead of the Sound and music computing Master at Aalborg University. Stefania received her PhD entitled “The sound of friction: computer models, playability and musical applications” from Stanford University in 2004, supervised by Professor Julius Smith III. Her research on sonic interaction design, sound for virtual and augmented reality with applications in health and culture can be found here: tinyurl.com/35wjk3jn

#### Talk Description:

**Physics based Sonic Interactions**

In this talk I will provide an overview of the physics based simulations that we have developed in recent years at the Multisensory Experience Lab at Aalborg University in Copenhagen, with applications on cultural heritage and technologies for people in need.

#### Workshop Description:

**Physics based sonic interactions in practice**

In the last decades several physical modelling techniques have been developed, such as waveguide models, mass-spring simulations, modal synthesis and finite difference schemes, to name a few. Moreover, these techniques have already been implemented in different software platforms such as Max, Faust, Juce, Super Collider, as well as commercial products such as SWAM by Audio Modelling. In this workshop we will look at recent developments in modelling musical instruments, discussing advantages and disadvantages of the different techniques. We will examine available tools and choose one case study to examine in depth.

#### Downloads/Requirements:
A laptop and your favourite audio programming software



### Romain Michon
#### Biography
Romain Michon is faculty researcher at INRIA in the Emeraude team, associate researcher at GRAME -- Centre National de Création Musicale in Lyon (France), and a lecturer at the Center for Computer Research in Music and Acoustics (CCRMA) at Stanford University (USA). He has been involved in the development of the Faust programming language since 2008 and he's part of the core Faust development team at GRAME. Beside that, Romain's research interests involve embedded systems for real-time audio processing, Human Computer Interaction (HCI), New Interfaces for Musical Expression (NIME), and physical modeling of musical instruments. He's currently leading the FAST project (https://fast.grame.fr) on facilitating the programming of FPGA platforms for real-time audio signal processing applications towards ultra-low latency.

#### Talk Description:

**Mesh2faust: From 3D Meshes to Faust Physical Models**

Tools like faust2unity greatly facilitate the use of Faust-written synthesizers and audio effects in Virtual Reality environments for procedural audio applications. Tighter connections can be established between what is seen and what is heard in these environments through the use of physical modeling. For instance, mesh2faust can convert a 3D mesh designed in any CAD software (i.e., SolidWorks, Blender, Rhino, OpenSCAD, etc.) or VR environment into a modal physical model implemented in Faust through finite element analysis. In this presentation, after giving some general background on the use of physical modeling in the context of procedural audio and VR, we demonstrate how 3D graphical objects can be turned into ready-to-use audio physical models using mesh2faust.

#### Workshop Description:

**Procedural Audio with Faust**

The workshop is a practical introduction to procedural audio and Faust programming. Different techniques of sound synthesis will be explored using in particular the new Faust physical modeling libraries. The workshop does not require the installation of any software except a recent web browser like Firefox or Chrome. All examples will be programmed directly in the web using the Faust IDE (https://faustide.grame.fr).


#### Downloads/Requirements:
A laptop with a recent version of Chrome or Firefox installed



### Ethan Geller
#### Biography
Audio Research Software Engineer at Facebook. I've worked on spatial audio for VR and I also compose and perform electronic and acoustic music.

#### Talk Description:

**title**

xxx

#### Workshop Description:

**title**

xxx

#### Downloads/Requirements:
xxx

