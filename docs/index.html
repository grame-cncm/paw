<!doctype html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css"
    integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">

  <link href="https://fonts.googleapis.com/css?family=Roboto|Roboto+Condensed&display=swap" rel="stylesheet">

  <link href="css/paw.css" rel="stylesheet">

  <title>Programmable Audio Workshop (PAW)</title>
</head>

<body>

  <header>
    <nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark">
      <a class="navbar-brand" href="#"><b>Programmable Audio Workshop</b></a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarCollapse"
        aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarCollapse">
        <ul class="navbar-nav mr-auto">
          <li class="nav-item">
            <a class="nav-link" href="#about">About</a>
          </li>
          <li class="nav-item dropdown">
            <a data-toggle="dropdown" class="nav-link dropdown-toggle" href="">Program</a>
            <div class="dropdown-menu">
              <a class="dropdown-item" href="#program-overview">Overview</a>
              <a class="dropdown-item" href="#program-details">Details</a>
              <a class="dropdown-item" href="#speakers">About the Speakers</a>
            </div>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="#registration-contact">Registration/Contact</a>
          </li>
        </ul>
      </div>
    </nav>
  </header>

  <main role="main">

    <div id="myCarousel" class="carousel slide" data-ride="carousel">
      <div class="carousel-inner">
        <div class="carousel-item active">
          <img class="first-slide" src="img/banner.jpg" alt="First slide">
          <div class="container">
            <div class="carousel-caption">
              <a style="font-size: 40px;" class="btn btn-lg btn-primary" href="#program-overview" role="button">Check the Program Out!</a>
            </div>
          </div>
        </div>
        <!-- <div class="carousel-item">
          <img class="second-slide" src="img/paw1.jpg" alt="Second slide">
        </div> -->
      </div>
      <!--
      <a class="carousel-control-prev" href="#myCarousel" role="button" data-slide="prev">
        <span class="carousel-control-prev-icon" aria-hidden="true"></span>
        <span class="sr-only">Previous</span>
      </a>
      <a class="carousel-control-next" href="#myCarousel" role="button" data-slide="next">
        <span class="carousel-control-next-icon" aria-hidden="true"></span>
        <span class="sr-only">Next</span>
      </a>
    -->
    </div>


    <div class="container">
      <h1 id="about">PAW 2022<br><i>Networked and Embedded Audio Systems</i><br><small>CITI Lab @ INSA Lyon (France) - Dec. 3, 2022</small></h1>

      <p>The Programmable Audio Workshop (PAW) is a yearly one day event gathering members of the programmable audio community around scientific talks and hands-on workshops. The 2022 edition of PAW will be hosted by the <a href="https://team.inria.fr/emeraude">INRIA/INSA/GRAME-CNCM Emeraude Team</a> at the <a href="https://www.citi-lab.fr/">CITI Lab of INSA Lyon</a> (France) on December 3d, 2022. The theme of PAW this year is "Networked and Embedded Audio Systems" with a strong focus on spatial audio and Field-Programmable Gate Arrays (FPGAs).</p>

      <p>PAW is completely free, but the number of seats is limited: please, register as soon as possible at <a href="TODO">PAW 2022 REGISTRATION</a>.</p>

      <hr>

      <h1 id="program-overview">Program Overview</h1>

      <p>To be published soon...</p>

      <!--
      <div class="row">

        <div class="col">
          <h3>Morning: Talks</h3>

          <table class="table">
            <tr>
              <td>
                <div class="time"></div>
              </td>
              <td><strong>Amphithéâtre R. Mouterde</strong></td>
            </tr>
            <tr>
              <td>
                <div class="time">09:00</div>
              </td>
              <td><em>Registration</em></td>
            </tr>
            <tr>
              <td>
                <div class="time">09:30</div>
              </td>
              <td><a href="#welcome">Welcome</a><br>
                <a href="#orlarey">Yann Orlarey</a><br>
                (Scientific Director, GRAME CNCM -- Lyon, France)
              </td>
            </tr>
            <tr>
              <td>
                <div class="time">09:50</div>
              </td>
              <td><a href="#ethantalk">Audio in Unreal with Faust</a>
                <br><a href="#ethanbio">Ethan Geller</a>
                <br>(Audio Research Software Engineer, Meta/Facebook, USA)
              </td>
            </tr>
            <tr>
              <td>
                <div class="time">10:10</div>
              </td>
              <td><a href="#michaeltalk">Video Game Engine as Media Creation Swiss Army Knife</a>
                <br><a href="#michaelbio">Michael Bolufer</a> and <a href="#gabrielbio">Gabriel Malgouyard</a>
                <br>(Technical Director at Plip! Animation and Studio Manette and Software Artisan, Realtime Multimedia
                Projects.

              </td>
            </tr>
            <tr>
              <td>
                <div class="time">10:30</div>
              </td>
              <td><em>Coffee Break</em></td>
            </tr>
            <tr>
              <td>
                <div class="time">11:00</div>
              </td>
              <td><a href="#stefaniatalk">Physics Based Sonic Interactions</a>
                <br><a href="#stefaniabio">Stefania Serafin</a>
                <br>(Professor of Sonic Interaction Design, Aalborg University)
              </td>
            </tr>
            <tr>
              <td>
                <div class="time">11:20</div>
              </td>
              <td><a href="#robtalk">Virtual Musical Instrument Design for the 21st Century</a>
                <br><a href="#robbio">Rob Hamilton</a>
                <br>(Head of the Department of Arts, Rensselaer Polytechnic Institute, USA)
              </td>
            </tr>
            <tr>
              <td>
                <div class="time">11:40</div>
              </td>
              <td><a href="#romaintalk">Mesh2faust: From 3D Meshes to Faust Physical Models</a>
                <br><a href="#romainbio">Romain Michon</a>
                <br>(Faculty Researcher at INRIA (Emeraude team), Associate Researcher at GRAME)
              </td>
            </tr>

            <tr>
              <td>
                <div class="time">12:00</div>
              </td>
              <td><a href="#davidtalk">Spatial audio in Unity for an interactive immersive space</a>
                <br><a href="#davidbio">David-Alexandre Chanel</a>
                <br>(THEORIZ / Augmenta, Lyon, France)
              </td>
            </tr>


            <tr>
              <td>
                <div class="time">12:20</div>
              </td>
              <td><em>Lunch Break</em></td>
            </tr>
          </table>
        </div>
        <div class="col">
          <h3>Afternoon: Workshops</h3>
          <table class="table">
            <tr>
              <td></td>
              <td><strong>Amphithéâtre R. Mouterde</strong></td>
            </tr>
            <tr>
              <td>
                <div class="time">12:20</div>
              </td>
              <td><em>Lunch Break</em></td>
            </tr>

            <tr>
              <td>
                <div class="time">14:00</div>
              </td>
              <td><a href="#romainworkshop">Procedural Audio with Faust</a>
                <br><a href="#romainbio">Romain Michon</a>
                <br>(Faculty researcher at INRIA, Associate Researcher at GRAME)
              </td>
            </tr>
            <tr>
              <td>
                <div class="time">15:00</div>
              </td>
              <td><a href="#stefaniaworkshop">Physics Based Sonic Interactions in Practice</a>
                <br><a href="#stefaniabio">Stefania Serafin</a>
                <br>(Professor of Sonic Interaction Design, Aalborg University)
              </td>
            </tr>
            <tr>
              <td>
                <div class="time">16:00</div>
              </td>
              <td><em>Coffee Break</em></td>

            </tr>
            <tr>
              <td>
                <div class="time">16:30</div>
              </td>
              <td><a href="#ethanworkshop">Procedurally Spawned Faust Synths in Unreal</a>
                <br><a href="#ethanbio">Ethan Geller</a>
                <br>(Audio Research Software Engineer, Meta/Facebook, USA)
              </td>
            </tr>
            <tr>
              <td>
                <div class="time">17:30</div>
              </td>
              <td><a href="#robworkshop">Building Interactive Procedural Music Systems for Unreal Engine 4</a>
                <br><a href="#robbio">Rob Hamilton</a>
                <br>(Head of the Department of Arts, Rensselaer Polytechnic Institute, USA)
              </td>
            </tr>
            <tr>
              <td>
                <div class="time">18:30</div>
              </td>
              <td><em>END</em></td>

            </tr>

          </table>

        </div>
      </div>
      -->

      <hr>

      <h1 id="program-details">Program Details</h1>

      <h2><a href="TODO">Maxime Popoff</a>: High-Level Programming of FPGAs with FAUST for Real-Time Audio Signal Processing Applications</h2>

      <p>Field Programmable Gate Arrays (FPGAs) are very powerful embedded platforms that present significant advantages over other types of processors for real-time audio signal processing applications. Their design makes them very suitable for high parallelization and ultra fast data processing, enabling unequaled performances for audio DSP in terms of latency, throughput, sampling rate, and number of channels.</p>
      <p>However, programming them is complex and out of reach to non-specialized engineers as well as to most people in the audio community. With the aim of having a comprehensive environment to program audio DSP on FPGAs, we present a fully open-source system that compiles any FAUST program down to FPGA hardware and up to actual sound production.</p>
      <p>Our platform can be used for a wide range of applications and is highly configurable (i.e., sampling rate, number of channels, control interface, etc.).</p>

      <h2><a href="#rushton">Thomas Rushton</a>: Microcontroller-Based Network Client Towards Distributed Spatial Audio</h2>

      <p>Rising interest in virtual and augmented reality experiences has put increased focus on research into sophisticated audio spatialisation techniques such as Wave Field Synthesis and Ambisonics. These techniques typically call for the use of large numbers of loudspeakers and a centralised digital signal processing (DSP) system; as such they are limited by the bandwidth/throughput of that system, and can be very costly, relying on specialist hardware for delivering multichannel audio output.</p>
      <p>We propose a hardware module, based on a low-cost microcontroller, that can receive audio and control-data streams over Ethernet and deliver output to connected loudspeakers. Though reliant on a central server to send data streams to the clients, part of the DSP required to implement various spatialisation techniques takes place directly on the module, thus representing a distributed computing approach. The system is lightweight, open-source, generic in application, and scalable to large numbers of clients. In addition to spatial audio implementations, it can support and enhance -- with its accessibility and low-latency -- the kind of remote rehearsal and concert situations that rose to prominence during the COVID-19 pandemic.</p>

      <!--

      <h3>09:00-09:30, Registration</h3>

      <h2>Morning Talks (Amphithéâtre R. Mouterde)</h2>

      <h3 id="welcome">09:30-09:50, <a href="">Welcome</a> </h3>
      <h4><a href="#Yann">Yann Orlarey</a> (Scientific Director, GRAME CNCM -- Lyon, France)</h4>



      <h3 id="ethantalk">09:50-10:10, <a href="">Audio in Unreal with Faust </a> <a
          href="https://www.youtube.com/watch?v=CsPUdRVMs_I&list=PLwAe7sHp68Sk4t0kpYPh5tn0nZGO9wZb4">[video]</a>
      </h3>
      <h4><a href="#ethanbio">Ethan Geller</a> (Audio Research Software Engineer, Meta/Facebook, USA)</h4>
      <p>An introduction on audio in Unreal and how it could interact with Faust.</p>




      <h3 id="michaeltalk">10:10-10:30, <a href="">Video Game Engine as Media Creation Swiss Army Knife</a> <a
          href="https://www.youtube.com/watch?v=3wj3byGO1Zg&list=PLwAe7sHp68Sk4t0kpYPh5tn0nZGO9wZb4&index=2">[video]</a>
      </h3>

      <h4><a href="#michaelbio">Michael Bolufer</a> (Technical director at Plip! Animation and Studio Manette) and <a
          href="#gabrielbio">Gabriel Malgouyard</a> (Software Artisan, Realtime Multimedia Projects.)</h4>

      <p>From fully featured AAA game engine to open source tools libraries, video game tools of all kinds now
        constitute
        a rich and varied ecosystem. Many of these tools can be diverted from their original usage and relied upon as a
        basis for realtime media creation and especially audio. In the animation studio "Studio Manette", it is
        daily demonstrated with their production pipeline fully based on typical video game patterns and tools.</p>


      <h3>10:30-11:00, Coffee Break</h3>


      <h3 id="stefaniatalk">11:00-11:20, <a href="">Physics Based Sonic Interactions</a> <a
          href="https://www.youtube.com/watch?v=D3ytM9vvx00&list=PLwAe7sHp68Sk4t0kpYPh5tn0nZGO9wZb4&index=3">[video]</a>
      </h3>

      <h4><a href="#stefaniabio">Stefania Serafin</a> (Professor of Sonic Interaction Design, Aalborg University)</h4>

      <p>In this talk I will provide an overview of the physics based simulations that we have developed in recent years
        at the Multisensory Experience Lab at Aalborg University in Copenhagen, with applications on cultural heritage
        and technologies for people in need.
      </p>

      <h3 id="robtalk">11:20-11:40, <a href="">Virtual Musical Instrument Design for the 21st Century</a> <a
          href="https://www.youtube.com/watch?v=tamTAXPLHK0&list=PLwAe7sHp68Sk4t0kpYPh5tn0nZGO9wZb4&index=4">[video]</a>
      </h3>

      <h4><a href="#robbio">Rob Hamilton</a> (Head of the Department of Arts, Rensselaer Polytechnic Institute, USA)
      </h4>

      <p>Over the past decade, consumer-based virtual reality hardware and software platforms have become significantly
        more
        affordable and accessible to the general public. At the same time, virtual and augmented reality development
        toolkits
        grounded in game and mobile application design paradigms have similarly become more user friendly, opening up
        opportunities for artists, musicians and creatives of all backgrounds to help shape the look, feel and, perhaps
        most
        importantly, the sound of the ‘metaverse’ writ large. This talk will explore the role of musicians and digital
        luthiers
        alike in the field of Musical XR, targeting the creation and composition of dynamic and procedural real-time
        musical
        instruments and systems.</p>


      <h3 id="romaintalk">11:40-12:00, <a href="">Mesh2faust: From 3D Meshes to Faust Physical Models</a> <a
          href="https://www.youtube.com/watch?v=kB8lhlLRD3o&list=PLwAe7sHp68Sk4t0kpYPh5tn0nZGO9wZb4&index=5">[video]</a>
      </h3>

      <h4><a href="#romainbio">Romain Michon</a> (Faculty Researcher at INRIA (Emeraude team), Associate Researcher at
        GRAME)
      </h4>

      <p>Tools like faust2unity greatly facilitate the use of Faust-written synthesizers and audio effects in Virtual
        Reality environments for procedural audio applications. Tighter connections can be established between what is
        seen and what is heard in these environments through the use of physical modeling. For instance, mesh2faust can
        convert a 3D mesh designed in any CAD software (i.e., SolidWorks, Blender, Rhino, OpenSCAD, etc.) or VR
        environment into a modal physical model implemented in Faust through finite element analysis. In this
        presentation, after giving some general background on the use of physical modeling in the context of procedural
        audio and VR, we demonstrate how 3D graphical objects can be turned into ready-to-use audio physical models
        using mesh2faust.
      </p>


      <h3 id="davidtalk">12:00-12:20, <a href="">Spatial audio in Unity for an interactive immersive space</a> <a
          href="https://www.youtube.com/watch?v=75obOEZc6MA&list=PLwAe7sHp68Sk4t0kpYPh5tn0nZGO9wZb4&index=6">[video]</a>
      </h3>
      <h4><a href="#davidbio">David-Alexandre Chanel</a> (THEORIZ / Augmenta, Lyon, France)</h4>
      <p>
        David-Alexandre will talk about the challenges and constraints of designing and implementing real time
        spatialized sound in the Unity engine.
      </p>

      <h3>12:20-14:00, Lunch Break</h3>

      <h2>Afternoon Workshops</h2>

      <h3 id="romainworkshop">14:00-15:00, <a href="#romainworkshop">Procedural Audio with Faust</a> <a
          href="https://www.youtube.com/watch?v=XKEhSgdnE4o&list=PLwAe7sHp68Sk4t0kpYPh5tn0nZGO9wZb4&index=7">[video]</a>
      </h3>

      <h4><a href="#romainbio">Romain Michon</a> (Faculty Researcher at INRIA (Emeraude team), Associate Researcher at
        GRAME)</h4>

      <p>The workshop is a practical introduction to procedural audio and Faust programming. Different techniques of
        sound synthesis will be explored using in particular the new Faust physical modeling libraries. The workshop
        does not require the installation of any software except a recent web browser like Firefox or Chrome. All
        examples will be programmed directly in the web using the Faust IDE (https://faustide.grame.fr).</p>



      <h3 id="stefaniaworkshop">15:00-16:00, <a href="#stefaniaworkshop">Physics Based Sonic Interactions in
          Practice</a> <a
          href="https://www.youtube.com/watch?v=_eFMg8CGNQA&list=PLwAe7sHp68Sk4t0kpYPh5tn0nZGO9wZb4&index=8">[video]</a>
      </h3>

      <h4><a href="#stefaniabio">Stefania Serafin</a> (Professor of Sonic Interaction Design, Aalborg University)</h4>

      <p>In the last decades several physical modelling techniques have been developed, such as waveguide models,
        mass-spring simulations, modal synthesis and finite difference schemes, to name a few. Moreover, these
        techniques have already been implemented in different software platforms such as Max, Faust, Juce, Super
        Collider, as well as commercial products such as SWAM by Audio Modelling. In this workshop we will look at
        recent developments in modelling musical instruments, discussing advantages and disadvantages of the different
        techniques. We will examine available tools and choose one case study to examine in depth.</p>

      <h3>16:00-16:30, Coffee Break</h3>

      <h3 id="ethanworkshop">16:30-17:30, <a href="#ethanworkshop">Procedurally Spawned Faust Synths in Unreal</a> <a
          href="https://www.youtube.com/watch?v=2TlXPlECzwM&list=PLwAe7sHp68Sk4t0kpYPh5tn0nZGO9wZb4&index=9">[video]</a>
      </h3>

      <h4><a href="#ethanbio">Ethan Geller</a> (Audio Research Software Engineer, Meta/Facebook, USA)</h4>

      <p>
        In this presentation, we are going to add a .dsp object as an audio source in Unreal, procedurally spawn
        instances of
        it, and procedurally set parameters on those instances to create a diffuse, procedurally generated audiovisual
        experience. Before this presentation starts it is recommended that you install Unreal Engine 5 and have some way
        to
        compile `faust2api` on your computer.
      </p>


      <h3 id="robworkshop">17:30-18:30, <a href="#robworkshop">Building Interactive Procedural Music Systems for Unreal
          Engine 4</a> <a
          href="https://www.youtube.com/watch?v=7y9ouSVyWK4&list=PLwAe7sHp68Sk4t0kpYPh5tn0nZGO9wZb4&index=10">[video]</a>
      </h3>

      <h4><a href="#robbio">Rob Hamilton</a> (Head of the Department of Arts, Rensselaer Polytechnic Institute, USA)
      </h4>

      <p>For artists and designers seeking to build software-based dynamic and procedural audio and music systems, Epic
        Games’ Unreal 4 gaming engine offers a robust and battle-tested codebase optimized for real-time multi-user
        interaction. Capable of rendering visual assets with astonishing clarity and realism, Unreal 4 also boasts
        native Open Sound Control (OSC) support, as well as a suite of native procedural audio components for real-time
        audio synthesis. This workshop will explore the use of Unreal Engine 4 for building interactive musical systems
        using Unreal’s Blueprint workflow programming environment, OSC, and Unreal’s own synthesis components.</p>

      -->


      <hr>


      <h1 id="speakers">About the Speakers</h1>

      <h4 id="rushton"><a href="#">Thomas Rushton</a></h4>
      <p>Thomas Rushton is a student on the Sound and Music Computing MSc program at Aalborg University in Copenhagen. Currently an intern on Inria's EMERAUDE (Embedded Programmable Audio Systems) team, his work on digital musical instrument design has appeared in the proceedings of 2022's SMC conference; he was also a contributor to the 2022 Interactive Sonification workshop, presenting his work on interactive auditory biofeedback for runners.</p>

      <h1 id="registration-contact">Registration/Contact</h1>
      <p><b>Participants must register online</b>: <a href="TODO">PAW 2022 REGISTRATION</a>. Registration is <b>free</b> within the limit of available seats.</p>
      <p>Feel free to send your questions to <a href="#">paw_at_grame_dot_fr</a>.</p>
    </div>

    <footer class="footer">
      <div class="container footer-content">
        <div id="logos" class="logos">
          <a href="https://faust.grame.fr"><img src=img/logoFaust.png width=25%></a>
          <a href="https://inria.fr"><img src=img/logoInria.png width=25%></a>
          <a href="https://www.insa-lyon.fr"><img src=img/logoInsa.png width=25%></a>
          <a href="http://grame.fr"><img src=img/logoGrame.png width=20%></a>
        </div>
        <div class="copyright">
          <hr>
          <p style="text-align:center;">Made with ♥ by <a href="https://team.inria.fr/emeraude">Emeraude</a></p>
        </div>
      </div>
    </footer>

  </main>

  <!-- Optional JavaScript -->
  <!-- jQuery first, then Popper.js, then Bootstrap JS -->
  <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"
    integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo"
    crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js"
    integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49"
    crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js"
    integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy"
    crossorigin="anonymous"></script>
</body>

</html>
